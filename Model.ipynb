{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,precision_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score,auc\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=pd.read_csv(\"data\\\\test.csv\",sep=',')\n",
    "data_train=pd.read_csv(\"data\\\\train.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lamou\\Downloads\\M2_MOSEF_S1\\Data Mining\\Projet_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:32:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9091831995571634\n",
      "Accuracy: 0.8806666666666667\n",
      "Confusion Matrix:\n",
      " [[3411  192]\n",
      " [ 345  552]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "\n",
    "# Étape 1 : Préparez les données\n",
    "X = data_train.drop(columns=['Exited'])  # Toutes les colonnes sauf 'Exited' pour les variables explicatives\n",
    "y = data_train['Exited']                 # Cible (1 = churn, 0 = non-churn)\n",
    "\n",
    "# Étape 2 : Divisez data_train en sous-ensembles d'entraînement et de validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Étape 3 : Encodage des variables catégorielles\n",
    "# Supprimez les colonnes inutiles\n",
    "if 'Surname' in X_train.columns:\n",
    "    X_train = X_train.drop(columns=['Surname'])\n",
    "    X_val = X_val.drop(columns=['Surname'])\n",
    "\n",
    "# Encodez les variables catégorielles en utilisant One-Hot Encoding\n",
    "categorical_columns = [col for col in ['Geography', 'Gender'] if col in X_train.columns]\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_columns, drop_first=True)\n",
    "X_val = pd.get_dummies(X_val, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Assurez-vous que les colonnes de X_train et X_val sont les mêmes après l'encodage\n",
    "X_val = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Étape 4 : Entraînez le modèle XGBoost\n",
    "model = xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Étape 5 : Prédisez les probabilités pour l'ensemble de validation\n",
    "y_pred_proba = model.predict_proba(X_val)[:, 1]  # Probabilité pour la classe 1 (churn)\n",
    "y_pred = model.predict(X_val)                     # Prédictions de classes pour d'autres métriques\n",
    "\n",
    "# Calcul de l'AUC pour évaluer la capacité du modèle à distinguer entre churn et non-churn\n",
    "auc_score = roc_auc_score(y_val, y_pred_proba)\n",
    "print(\"AUC:\", auc_score)\n",
    "\n",
    "# Calcul de la précision\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Matrice de confusion pour mieux comprendre les erreurs de classification\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id    Exited\n",
      "0   4747  0.000768\n",
      "1  11140  0.218810\n",
      "2    404  0.085640\n",
      "3   8707  0.045092\n",
      "4   5046  0.012833\n"
     ]
    }
   ],
   "source": [
    "# Créez sample_submission en copiant l'identifiant 'id' de data_train pour les échantillons de validation\n",
    "sample_submission = data_train[['id']].iloc[y_val.index].copy().reset_index(drop=True)\n",
    "\n",
    "# Ajoutez la colonne 'Churn_Probability' de proba_df à sample_submission\n",
    "sample_submission[\"Exited\"] = y_pred_proba  # Ajout des probabilités de churn\n",
    "\n",
    "# Affichez les premières lignes pour vérifier\n",
    "print(sample_submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"sample_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id    Exited\n",
      "0  15000  0.060819\n",
      "1  15001  0.000460\n",
      "2  15002  0.001177\n",
      "3  15003  0.919986\n",
      "4  15004  0.014336\n"
     ]
    }
   ],
   "source": [
    "# Préparation de data_test pour les prédictions\n",
    "X_test = data_test.drop(columns=['id'])  # Suppression de la colonne 'id' si elle n'est pas une variable explicative\n",
    "\n",
    "# Suppression de colonnes inutiles dans data_test\n",
    "if 'Surname' in X_test.columns:\n",
    "    X_test = X_test.drop(columns=['Surname'])\n",
    "\n",
    "# Encodage des variables catégorielles dans data_test\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Assurez-vous que les colonnes de X_test correspondent à celles de X_train après l'encodage\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Prédisez les probabilités pour data_test\n",
    "y_test_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilité de churn pour chaque client dans data_test\n",
    "\n",
    "# Créez sample_submission avec 'id' et 'Churn_Probability'\n",
    "sample_submission_test = data_test[['id']].copy()  # Copie uniquement la colonne 'id' de data_test\n",
    "sample_submission_test[\"Exited\"] = y_test_pred_proba  # Ajout des probabilités de churn\n",
    "\n",
    "# Affichez les premières lignes de sample_submission pour vérification\n",
    "print(sample_submission_test.head())\n",
    "\n",
    "# Optionnel : Exportez sample_submission en CSV\n",
    "sample_submission_test.to_csv(\"sample_submission_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lamou\\Downloads\\M2_MOSEF_S1\\Data Mining\\Projet_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:50:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC after hyperparameter tuning: 0.9248192466887033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'colsample_bytree': [0.3, 0.7, 1.0],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'min_child_weight': [1, 5, 10]\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=20, scoring='roc_auc', cv=3, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred_proba_best = best_model.predict_proba(X_val)[:, 1]\n",
    "auc_best = roc_auc_score(y_val, y_pred_proba_best)\n",
    "print(\"Best AUC after hyperparameter tuning:\", auc_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lamou\\Downloads\\M2_MOSEF_S1\\Data Mining\\Projet_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:51:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lamou\\Downloads\\M2_MOSEF_S1\\Data Mining\\Projet_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:51:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lamou\\Downloads\\M2_MOSEF_S1\\Data Mining\\Projet_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:51:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lamou\\Downloads\\M2_MOSEF_S1\\Data Mining\\Projet_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:51:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lamou\\Downloads\\M2_MOSEF_S1\\Data Mining\\Projet_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:51:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated AUC scores: [0.92274519 0.92698229 0.91865707 0.92311515 0.93091537]\n",
      "Average AUC: 0.9244830133817155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
    "auc_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(\"Cross-validated AUC scores:\", auc_scores)\n",
    "print(\"Average AUC:\", auc_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id    Exited\n",
      "0  15000  0.166050\n",
      "1  15001  0.058086\n",
      "2  15002  0.059625\n",
      "3  15003  0.586088\n",
      "4  15004  0.081252\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Créez sample_submission avec 'id' et 'Churn_Probability'\n",
    "sample_submission_test_best = data_test[['id']].copy()  # Copie uniquement la colonne 'id' de data_test\n",
    "sample_submission_test_best[\"Exited\"] = y_pred_proba_best  # Ajout des probabilités de churn\n",
    "\n",
    "# Affichez les premières lignes de sample_submission pour vérification\n",
    "print(sample_submission_test_best.head())\n",
    "\n",
    "# Optionnel : Exportez sample_submission en CSV\n",
    "sample_submission_test_best.to_csv(\"sample_submission_test_best.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
